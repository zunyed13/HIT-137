from typing import Optional, List, Dict, Any
from pathlib import Path
from transformers import pipeline # type: ignore
from core.mixins import LoggingMixin, ValidationMixin # type: ignore
from core.decorators import timed, requires_input # type: ignore


class BaseAdapter(LoggingMixin, ValidationMixin):
    def __init__(self) -> None:
        super().__init__()
        self.pipe = None  # lazy init
        self._is_loaded = False

    def _ensure_loaded(self):
        if self.pipe is None or not self._is_loaded:
            raise RuntimeError(
                "Pipeline not loaded. Call load() method before running operations."
            )

    @property
    def is_loaded(self) -> bool:
        """Check if the model is loaded and ready."""
        return self.pipe is not None and self._is_loaded

    def unload(self):
        """Unload the model to free memory."""
        self.pipe = None
        self._is_loaded = False
        self.log("Model unloaded.")


class GPT2TextAdapter(BaseAdapter):
    def __init__(self, model_name: str = "openai-community/gpt2", device: Optional[str] = None):
        super().__init__()
        self.model_name = model_name
        self.device = device

    @timed
    def load(self):
        """Load the text generation pipeline."""
        self.log(f"Loading text-generation pipeline: {self.model_name}")
        try:
            self.pipe = pipeline(
                "text-generation", 
                model=self.model_name, 
                device=self.device
            )
            self._is_loaded = True
            self.log("Text generation pipeline loaded successfully.")
        except Exception as e:
            self.log(f"Error loading pipeline: {e}", level="error")
            raise
        return self

    @timed
    @requires_input
    def run(self, prompt: str, max_new_tokens: int = 60, do_sample: bool = True, 
            temperature: float = 0.8, **kwargs) -> List[Dict[str, Any]]:
        """
        Generate text based on the prompt.
        
        Args:
            prompt: Input text prompt
            max_new_tokens: Maximum number of tokens to generate
            do_sample: Whether to use sampling
            temperature: Sampling temperature
            **kwargs: Additional pipeline parameters
            
        Returns:
            List of generated text results
        """
        self._ensure_loaded()
        
        self.validate_string(prompt, "prompt")
        self.validate_positive_int(max_new_tokens, "max_new_tokens")
        self.validate_float_range(temperature, 0.0, 2.0, "temperature")
        
        self.log(f"Generating text with {max_new_tokens} max tokens")
        
        return self.pipe(
            prompt,
            max_new_tokens=max_new_tokens,
            do_sample=do_sample,
            temperature=temperature,
            **kwargs
        )

    def generate_text(self, prompt: str, **kwargs) -> str:
        """Convenience method to get generated text as string."""
        results = self.run(prompt, **kwargs)
        return results[0]['generated_text']


class ViTGPT2CaptionAdapter(BaseAdapter):
    def __init__(self, model_name: str = "nlpconnect/vit-gpt2-image-captioning", 
                 device: Optional[str] = None):
        super().__init__()
        self.model_name = model_name
        self.device = device

    @timed
    def load(self):
        """Load the image captioning pipeline."""
        self.log(f"Loading image-to-text pipeline: {self.model_name}")
        try:
            self.pipe = pipeline(
                "image-to-text", 
                model=self.model_name, 
                device=self.device
            )
            self._is_loaded = True
            self.log("Image captioning pipeline loaded successfully.")
        except Exception as e:
            self.log(f"Error loading pipeline: {e}", level="error")
            raise
        return self

    @timed
    @requires_input
    def run(self, image_path: str, max_new_tokens: int = 30, **kwargs) -> List[Dict[str, Any]]:
        """
        Generate caption for an image.
        
        Args:
            image_path: Path to the image file
            max_new_tokens: Maximum number of tokens for caption
            **kwargs: Additional pipeline parameters
            
        Returns:
            List of caption results
        """
        self._ensure_loaded()
        
        self.ensure_file_exists(image_path)
        self.validate_positive_int(max_new_tokens, "max_new_tokens")
        
        self.log(f"Generating caption for image: {image_path}")
        
        return self.pipe(image_path, max_new_tokens=max_new_tokens, **kwargs)

    def generate_caption(self, image_path: str, **kwargs) -> str:
        """Convenience method to get caption as string."""
        results = self.run(image_path, **kwargs)
        return results[0]['generated_text']


# Example usage and testing
if __name__ == "__main__":
    # Example usage
    text_gen = GPT2TextAdapter()
    caption_gen = ViTGPT2CaptionAdapter()
    
    # Test text generation
    try:
        result = text_gen.run("The future of AI is")
        print("Generated text:", result)
        
        # Or use convenience method
        text = text_gen.generate_text("Hello world", max_new_tokens=20)
        print("Generated text:", text)
        
    except Exception as e:
        print(f"Error: {e}")
    
    # Test caption generation (requires an actual image file)
    # try:
    #     caption = caption_gen.generate_caption("path/to/image.jpg")
    #     print("Generated caption:", caption)
    # except Exception as e:
    #     print(f"Error: {e}")
